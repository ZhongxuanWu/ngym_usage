{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "import seaborn as sns\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path \n",
    "data_pth = '/home/jordi/Repos/pkgs/data/'\n",
    "files = [str(x) for x in Path(data_pth).glob('**/*.npz')]\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 1st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sublist = sorted([x for x in files if 'Romo-v0' in x]) # 'ReadySetGo'\n",
    "sublist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for algo in ['A2C', 'ACER', 'ACKTR']:\n",
    "    targ = sorted([x for x in sublist if algo in x])[0]\n",
    "    test = np.load(targ, allow_pickle=True)\n",
    "    print(algo)\n",
    "    for item in test.files:\n",
    "        print(f'{item} shape {test[item].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test=np.load('/home/jordi/Repos/pkgs/data/A2C_Romo-v0_0.npz', allow_pickle=True)\n",
    "test.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test['rewards'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,4))\n",
    "for i in range(test['rewards'].shape[1]):\n",
    "    plt.plot(pd.Series(test['rewards'][:,i]).rolling(25).mean())\n",
    "\n",
    "plt.axhline(y=0, c='k', ls=':')\n",
    "plt.xlabel('dt')\n",
    "plt.ylabel('reward rolling average (win=25)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,4))\n",
    "for i in range(test['rewards'].shape[1]):\n",
    "    plt.plot(test['rewards'][:,i])\n",
    "\n",
    "plt.axhline(y=0, c='k', ls=':')\n",
    "plt.xlabel('dt')\n",
    "plt.ylabel('raw reward')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(test['rewards']).boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import neurogym as ngym\n",
    "len(ngym.all_tasks.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "toplot = []\n",
    "for task in ngym.all_tasks.keys():\n",
    "    try:\n",
    "        targfile = [x for x in files if (task in x) and ('ACER' in x) and (x.endswith('0.npz'))][0] # 'A2C'\n",
    "        toplot += [targfile]\n",
    "    except:\n",
    "        print(f'{task} not found')\n",
    "        continue\n",
    "    print(targfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test['rewards'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(toplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(nrows=len(toplot), sharex=True, figsize=(16, 4*len(toplot)))\n",
    "ax=ax.flatten()\n",
    "\n",
    "for j,item in enumerate(toplot):\n",
    "    test=np.load(item, allow_pickle=True)\n",
    "    rew = test['rewards'].squeeze()\n",
    "    ax[j].axhline(y=0, c='k', ls=':')\n",
    "    for i in range(rew.shape[1]):\n",
    "        ax[j].plot(pd.Series(rew[:,i]).rolling(25).mean())\n",
    "\n",
    "    ax[j].set_title(item.split('/')[-1])\n",
    "    ax[j].set_ylabel('rolling(w=25)reward')\n",
    "\n",
    "ax[j].set_xlabel('dt')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(nrows=len(toplot),ncols=2,sharex=True, figsize=(16*2, 4*len(toplot)))\n",
    "ax=ax.flatten()\n",
    "\n",
    "for j,item in enumerate(toplot):\n",
    "    j = j*2\n",
    "    test=np.load(item, allow_pickle=True)\n",
    "    \n",
    "    rew = test['rewards'].squeeze()\n",
    "    ax[j].axhline(y=0, c='k', ls=':')\n",
    "    ax[j+1].axhline(y=0, c='k', ls=':')\n",
    "    for i in range(rew.shape[1]):\n",
    "        ax[j].plot(rew[:,i])\n",
    "        ax[j+1].plot(pd.Series(rew[:,i]).rolling(25).mean())\n",
    "        \n",
    "    ax[j].set_title(item.split('/')[-1]+ 'reward per timestep')\n",
    "    ax[j].set_ylabel('rewards')\n",
    "    ax[j+1].set_title(item.split('/')[-1]+ ' rolling mean')\n",
    "    ax[j+1].set_ylabel('rolling(w=25)reward')\n",
    "\n",
    "ax[j].set_xlabel('dt')\n",
    "ax[j+1].set_xlabel('dt')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for j,item in enumerate(toplot):\n",
    "    test=np.load(item, allow_pickle=True)\n",
    "    print(test['rewards'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 2nd batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sl_list = sorted([x for x in files if os.path.split(x)[1].startswith('training')])\n",
    "sl_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d = np.load(sl_list[0], allow_pickle=True)\n",
    "d.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(nrows=int(len(sl_list)/2), ncols=3, sharex=True, figsize=(16*2, 4*len(sl_list)/2))\n",
    "#ax=ax.flatten()\n",
    "\n",
    "for j,item in enumerate(sl_list):\n",
    "    j = j//2\n",
    "    test=np.load(item, allow_pickle=True)\n",
    "    fname = item.split('/')[-2]\n",
    "    #ax[j].axhline(y=0, c='k', ls=':')\n",
    "    #ax[j+1].axhline(y=0, c='k', ls=':')\n",
    "    for i, metric in enumerate(['acc','loss', 'perf']):\n",
    "        #ax[j][].axhline(y=0, c='k', ls=':')\n",
    "        ax[j][i].plot(test[metric], label=f'{fname} {metric}')\n",
    "        ax[j][i].legend()\n",
    "        #ax[j+1].plot(pd.Series(rew[:,i]).rolling(25).mean())\n",
    "        \n",
    "    # ax[j].set_title(item.split('/')[-1]+ 'reward per timestep')\n",
    "    # ax[j].set_ylabel('rewards')\n",
    "    #ax[j+1].set_title(item.split('/')[-1]+ ' rolling mean')\n",
    "    ax[j][0].set_ylabel(fname[:-5])\n",
    "\n",
    "# ax[j].set_xlabel('dt')\n",
    "# ax[j+1].set_xlabel('dt')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# there are several tasks missing\n",
    "sl_list_working = [sl_list[i].split('/')[-2][:-5] for i in range(0, len(sl_list), 2)]\n",
    "sl_list_working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import neurogym as ngym\n",
    "sl_not_working = [x[:-3] for x in ngym.all_tasks.keys() if 'SL_'+x[:-3] not in sl_list_working]\n",
    "sl_not_working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a2cworking = list(set([os.path.split(x)[1][4:-6] for x in files if os.path.split(x)[1].startswith('A2C')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a2notworking = [x for x in ngym.all_tasks.keys() if x not in a2cworking]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(a2cworking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a2cworking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(ngym.all_tasks.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a2notworking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 3rd, RL (a2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a2cworking = sorted(a2cworking)\n",
    "a2cworking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(files[0])\n",
    "test = np.load(files[0], allow_pickle=True)\n",
    "test.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test['rewards'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(ncols=2, nrows=10, figsize=(9,28))\n",
    "ax=ax.flatten()\n",
    "for i in range(20):\n",
    "    ax[i].plot(test['rewards'][70000:,i])\n",
    "    ax[i].set_title(f'dim (:,{i})')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(files[2])\n",
    "test = np.load(files[2], allow_pickle=True)\n",
    "print(test['rewards'].shape)\n",
    "test.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "kek = np.array([[0,2,4,6],[1,3,5,7]])\n",
    "\n",
    "kek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "kek.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "kek.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test['rewards'].flatten().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(ncols=2, nrows=1, figsize=(15,6))\n",
    "ax[0].plot(np.arange(3000),test['rewards'].flatten()[:3000])\n",
    "ax[0].set_title('early training')\n",
    "ax[1].plot(np.arange(test['rewards'].size-3000,test['rewards'].size),test['rewards'].flatten()[-3000:])\n",
    "ax[1].set_title('late training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "[x for x in files if (a2cworking[0] in x) and ('A2C' in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# final list\n",
    "flist = sorted([x for x in files if x.endswith('0.npz') and ('A2C' in x)])\n",
    "len(flist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(nrows=20, ncols=2, sharey='row',figsize=(18,4*20))\n",
    "\n",
    "for i, targfile in enumerate(flist):\n",
    "    target = np.load(targfile, allow_pickle=True)\n",
    "    rews = target['rewards'].flatten()\n",
    "    taskname = os.path.split(targfile)[1][4:-6]\n",
    "    ax[i][0].plot(np.arange(1000), rews[:1000])\n",
    "    ax[i][1].plot(np.arange(rews.size-1000,rews.size), rews[-1000:])\n",
    "    ax[i][0].set_ylabel(f'{taskname} rewards')\n",
    "    \n",
    "ax[0][0].set_title('early training')\n",
    "ax[0][1].set_title('late training')\n",
    "ax[-1][0].set_xlabel('timestep')\n",
    "ax[-1][1].set_xlabel('timestep')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "flist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(nrows=20,figsize=(18, 4*20))\n",
    "\n",
    "for i, targfile in enumerate(flist):\n",
    "    target = np.load(targfile, allow_pickle=True)\n",
    "    rews = target['rewards'].flatten()\n",
    "    window = int(rews.size*0.01)\n",
    "    taskname = os.path.split(targfile)[1][4:-6]\n",
    "    ax[i].plot(pd.Series(rews).rolling(window).mean())\n",
    "    #ax[i][1].plot(np.arange(rews.size-1000,rews.size), rews[-1000:])\n",
    "    ax[i].set_ylabel(f'{taskname} rewards')\n",
    "    ax[i].set_title(f'{taskname} rewards (rolling window = {window})')\n",
    "    \n",
    "#x[0][0].set_title('early training')\n",
    "#x[0][1].set_title('late training')\n",
    "ax[-1].set_xlabel('step')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# test with flist[2]\n",
    "test = np.load(flist[2], allow_pickle=True)\n",
    "test.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for item in test.files:\n",
    "    print(item, test[item].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "kek = np.arange(4*3*2).reshape(4,3,2)\n",
    "kek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rews = test['rewards'].flatten()\n",
    "obs = test['observations'].reshape(-1,5)\n",
    "acts = test['actions'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nsteps=100\n",
    "f, ax = plt.subplots(nrows=3, ncols=1, figsize=(9,10), sharex=True)\n",
    "ax[0].imshow(obs[-nsteps:,:].T, aspect='auto')\n",
    "ax[0].set_title('task')\n",
    "ax[0].set_ylabel('obs')\n",
    "ax[1].plot(acts[-nsteps:], c='tab:blue', marker='+')\n",
    "ax[1].set_ylabel('acts')\n",
    "ax[2].plot(rews[-nsteps:], c='tab:red')\n",
    "ax[2].set_ylabel('rews')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flist[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for item in flist:\n",
    "    test = np.load(item, allow_pickle=True)\n",
    "    rews = test['rewards'].flatten()\n",
    "    obs = test['observations'].reshape(-1,test['observations'].shape[-1])\n",
    "    acts = test['actions'].flatten()\n",
    "    f, ax = plt.subplots(nrows=3, ncols=1, figsize=(9,10), sharex=True)\n",
    "    ax[0].imshow(obs[-nsteps:,:].T, aspect='auto')\n",
    "    ax[0].set_title(os.path.split(item)[1][:-6])\n",
    "    ax[0].set_ylabel('obs')\n",
    "    ax[1].plot(acts[-nsteps:], c='tab:blue', marker='+')\n",
    "    ax[1].set_ylabel('acts')\n",
    "    ax[2].plot(rews[-nsteps:], c='tab:red')\n",
    "    ax[2].set_ylabel('rews')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for item in test.files:\n",
    "    print(item, test[item].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for item in [rews, obs, acts]:\n",
    "    print(item.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(test['rewards'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nsteps = 100\n",
    "initial_s = 0\n",
    "test = np.load('/home/jordi/Repos/pkgs/neurotests/out/serrano2.npz', allow_pickle=True)\n",
    "if len(test['rewards'].shape)==3:\n",
    "    rews = test['rewards'].reshape(-1,test['rewards'].shape[-1]) #flatten()\n",
    "else:\n",
    "    rews = test['rewards'].flatten()\n",
    "    \n",
    "obs = test['observations'].reshape(-1,test['observations'].shape[-1])\n",
    "acts = test['actions'].reshape(-1,test['actions'].shape[-1])\n",
    "f, ax = plt.subplots(nrows=3, ncols=1, figsize=(9,10), sharex=True)\n",
    "ax[0].imshow(obs[initial_s:initial_s+nsteps,:].T, aspect='auto')\n",
    "ax[0].set_title('serrano')\n",
    "ax[0].set_ylabel('obs')\n",
    "ax[1].plot(acts[initial_s:initial_s+nsteps, 0], c='tab:blue', marker='+')\n",
    "ax[1].plot(acts[initial_s:initial_s+nsteps, 1], c='tab:orange', marker='+')\n",
    "ax[1].set_ylabel('acts')\n",
    "ax[1].axhline(y=0, c='grey', ls=':')\n",
    "ax[2].plot(rews[initial_s:initial_s+nsteps], c='tab:red')\n",
    "ax[2].set_ylabel('rews')\n",
    "ax[0].set_xlim([0,nsteps])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(rews==rews.max()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(acts[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rews.shape[0]/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = np.random.uniform(0.8, 1.2)\n",
    "\n",
    "\n",
    "print(round(a-0.01, 3), round(a+0.01, 3))\n",
    "\n",
    "print(round(a-0.01-0.03, 3), round(a+0.01+0.03, 3))\n",
    "print(f'range = {(0.01+0.03)*2} represents {(100*(0.01+0.03)*2)/0.4} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "100*np.isnan(acts).sum()/acts.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(9,3))\n",
    "plt.plot(pd.Series(rews).rolling(int(1e7*0.01)).mean())\n",
    "plt.ylabel('reward')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def our_reward(action, gt):\n",
    "    r = 1/((1+abs(action-gt))**2)\n",
    "    return r\n",
    "\n",
    "for i,j in tqdm(zip(np.random.uniform(-100,100,int(1e8)),np.random.uniform(0, 1., int(1e8)))):\n",
    "    if our_reward(i,j)>1:\n",
    "        print(f'got it with action={i} and gt={j}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 2nd BATCH (30th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import neurogym as ngym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# check integrity...\n",
    "# complete training should have .png\n",
    "ok_run_tasks = []\n",
    "pngs = list(set([str(x).split('/')[-2][:-2] for x in Path(data_pth).glob('**/*.png')]))\n",
    "print(pngs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.zeros((6,len(ngym.all_tasks.keys()))).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.columns = ['task', 'A2C', 'ACER', 'ACKTR', 'PPO2', 'SL']\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['task'] = sorted(list(ngym.all_tasks.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.iloc[:,1:]=False\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for algo in ['A2C', 'ACER', 'ACKTR', 'PPO2', 'SL']:\n",
    "    subset = [x[len(algo)+1:] for x in pngs if x.startswith(algo)]\n",
    "    #print(subset)\n",
    "    for item in subset:\n",
    "        df.loc[df.task==item, algo] = True\n",
    "        \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## PPO2: (old)minibatches error ~ not included in new bsls\n",
    "## ACKTR: still not enough time to finnish\n",
    "\n",
    "plt.figure(figsize=(2.5,13))\n",
    "plt.imshow(df.iloc[:,1:].values, aspect='auto')\n",
    "plt.yticks(np.arange(26),df['task'].values)\n",
    "plt.xticks(np.arange(5), ['A2C', 'ACER', 'ACKTR', 'PPO2', 'SL'], fontsize=8)\n",
    "plt.title('plotting integrity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "errors= {}\n",
    "\n",
    "# we discard the obvious ones which always fail\n",
    "for algo in ['A2C', 'ACER', 'SL']:\n",
    "    errors[algo]={}\n",
    "    for task in tqdm.tqdm(sorted(ngym.all_tasks.keys())):\n",
    "        if not df.loc[df.task==task, algo].values:\n",
    "            errors[algo][task] = 'pending'          \n",
    "            \n",
    "errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# idk why im generating this infernal nested dict\n",
    "errors['A2C']['AngleReproduction-v0'] = 'IndexError: index 5 is out of bounds for axis 1 with size 3 (keras.utils.to_categorical)'\n",
    "errors['A2C']['AntiReach-v0'] = 'IndexError: index 3 is out of bounds for axis 1 with size 3 (keras.utils.to_categorical)'\n",
    "errors['A2C']['Bandit-v0'] = \"AttributeError: 'Bandit' object has no attribute 'obs' || @ line 63, 42\"\n",
    "errors['A2C']['ChangingEnvironment-v0'] = \"fixed\"\n",
    "errors['A2C']['DawTwoStep-v0'] = \"AttributeError: 'DawTwoStep' object has no attribute 'hi_state' + TODOED\"\n",
    "# delayed match category:\n",
    "\"\"\"File \"/home/hcli64/hcli64348/neurogym/neurogym/envs/delaymatchcategory.py\", line 91, in new_trial\n",
    "    self.add_epoch('decision', after='test', last_epoch=True)\n",
    "  File \"/home/hcli64/hcli64348/neurogym/neurogym/core.py\", line 167, in add_epoch\n",
    "    duration = (self.timing_fn[epoch]() // self.dt) * self.dt\n",
    "KeyError: 'decision'\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "list(errors['SL'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 3rd batch (3rd Feb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import neurogym as ngym\n",
    "from neurogym.utils.plotting import plot_rew_across_training\n",
    "#builtint\n",
    "#test = '/home/jordi/Repos/pkgs/data/30th/A2C_ReadySetGo-v0_0'\n",
    "test = '/home/jordi/Repos/pkgs/data/30th/A2C_GNG-v0_0'\n",
    "\n",
    "plot_rew_across_training(folder=test, window=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "targ_dir = '/home/jordi/Repos/pkgs/data/30th/SL_CVLearning-v0_0/99/'\n",
    "targ = targ_dir+[x for x in os.listdir(targ_dir) if x.endswith('.npz')][0]\n",
    "targ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n = np.load(targ, allow_pickle=True)\n",
    "n.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n['reward'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(ngym.envs.ALL_ENVS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perf = pd.DataFrame(np.ones((len(ngym.envs.ALL_ENVS.keys()), 6)))\n",
    "perf.columns = ['task', 'A2C', 'ACER', 'ACKTR', 'PPO2', 'SL']\n",
    "perf['task'] = sorted(list(ngym.envs.ALL_ENVS.keys()))\n",
    "for col in ['A2C', 'ACER', 'ACKTR', 'PPO2', 'SL']:\n",
    "    perf[col] = np.nan\n",
    "perf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_perf(algo, task ,seeds=2, ntr=100000):\n",
    "    try:\n",
    "        perf = []\n",
    "        for i in range(seeds):\n",
    "            basedir = f'/home/jordi/Repos/pkgs/data/3rd/{algo}_{task}_{i}/{task[:-3]}_bhvr_data_{ntr}.npz' \n",
    "            n = np.load(basedir, allow_pickle=True)\n",
    "            perf += n['reward'].tolist()\n",
    "        return np.array(perf).mean()\n",
    "    except:\n",
    "        #print(f'crash with {algo} & {task}')\n",
    "        return np.nan\n",
    "    \n",
    "def get_perf_SL(task ,seeds=2, ntr=100000):\n",
    "    try:\n",
    "        perf = []\n",
    "        for i in range(seeds):\n",
    "            basedir = f'/home/jordi/Repos/pkgs/data/3rd/SL_{task}_{i}/{task[:-3]}_bhvr_data_1000.npz'  # forgot to add dir with iter\n",
    "            n = np.load(basedir, allow_pickle=True)\n",
    "            perf += n['reward'].tolist()\n",
    "        return np.array(perf).mean()\n",
    "    except:\n",
    "        #print(f'crash with {algo} & {task}')\n",
    "        return np.nan\n",
    "    \n",
    "for current_task in perf.task.values.tolist():\n",
    "    perf.loc[perf.task==current_task, 'SL'] = get_perf_SL(current_task)\n",
    "    for alg in ['A2C', 'ACER', 'ACKTR', 'PPO2']: # 'SL']:\n",
    "        #print(get_perf(alg, current_task))\n",
    "        perf.loc[perf.task==current_task, alg]=get_perf(alg, current_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(4,26))\n",
    "# plt.imshow(perf[['A2C', 'ACER', 'ACKTR', 'PPO2', 'SL']].values,aspect='auto')\n",
    "# plt.yticks(np.arange(perf.shape[0]),perf['task'].values)\n",
    "# plt.xticks(np.arange(5), ['A2C', 'ACER', 'ACKTR', 'PPO2', 'SL'], fontsize=8)\n",
    "# plt.title('performance @ 100k trials')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(5,26))\n",
    "sns.heatmap(perf[['A2C', 'ACER', 'ACKTR', 'PPO2', 'SL']].values, annot=True, fmt='.2f',ax=ax, cmap='viridis', cbar=False)\n",
    "# annot=np.flipud(nmat), fmt='.0f',ax=ax\n",
    "ax.set_yticks(np.arange(perf.shape[0])+0.5)\n",
    "ax.set_yticklabels([x[:-3] for x in perf['task'].values], rotation='horizontal')\n",
    "ax.set_xticks(np.arange(5)+0.5)\n",
    "ax.set_xticklabels(['A2C', 'ACER', 'ACKTR', 'PPO2', 'SL'], fontsize=8)\n",
    "ax.set_title('performance @ 100k trials')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def second_round(idx, col):\n",
    "    \"\"\"heheh\"\"\"\n",
    "    curr_task = perf.loc[idx, 'task']\n",
    "    all_perf = []\n",
    "    try:\n",
    "        for i in [0,1]: # seeds\n",
    "            d = f'/home/jordi/Repos/pkgs/data/3rd/{col}_{curr_task}_{i}/'\n",
    "            allfiles = [int(x.split('_')[-1][:-4]) for x in os.listdir(d) if x.endswith('.npz')]\n",
    "            targ = [x for x in os.listdir(d) if str(max(allfiles)) in x]\n",
    "            #print(targ)\n",
    "            arr = np.load(d+targ[0], allow_pickle=True)\n",
    "            all_perf += arr['reward'].tolist()\n",
    "\n",
    "        return np.array(all_perf).mean()\n",
    "    except Exception as e:\n",
    "        print(f'{curr_task} failed\\n{e}')\n",
    "        return np.nan\n",
    "        \n",
    "#perf['ACER'].isna()\n",
    "second_round(25, 'ACER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for curr_col in ['A2C', 'ACER', 'PPO2']:\n",
    "    for i in perf.loc[perf[curr_col].isna()].index.values:\n",
    "        perf.loc[i, curr_col] = second_round(i, curr_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#f = np.load('/home/jordi/Repos/pkgs/data/3rd/A2C_Detection-v0_0/Detection_bhvr_data_89000.npz', allow_pickle=True)\n",
    "f = np.load('/home/jordi/Repos/pkgs/data/3rd/A2C_DelayedComparison-v0_0/DelayedComparison_bhvr_data_100000.npz', allow_pickle=True)\n",
    "\n",
    "#f['reward'].mean()\n",
    "sns.distplot(f['reward'], kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#so apparently model is missing from many folders\n",
    "#import pathlib\n",
    "files = sorted([str(x) for x in Path('/home/jordi/Repos/pkgs/data/3rd/').glob('*0/model.zip')])\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# should be ok (ie model trained but need dataset >1000trials) in: \n",
    "# ReachingDelayResponse\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from neurogym.utils.plotting import plot_env\n",
    "import importlib\n",
    "from neurogym.custom_timings import ALL_ENVS_MINIMAL_TIMINGS\n",
    "import gym\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "\n",
    "\n",
    "\n",
    "def custom_plot_env(modelpath, num_steps_env=200):\n",
    "    root_str = os.path.split(modelpath)[0].split('/')[-1]\n",
    "    algo = root_str.split('_')[0]\n",
    "    task = root_str.split('_')[1]\n",
    "    seed = root_str.split('_')[-1]\n",
    "    ngym_kwargs = {'dt':100, 'timing': ALL_ENVS_MINIMAL_TIMINGS[task]}\n",
    "    env = gym.make(task, **ngym_kwargs)\n",
    "    env = DummyVecEnv([lambda: env])\n",
    "    pkg = importlib.import_module('stable_baselines') #+algo) \n",
    "    module = getattr(pkg, algo)\n",
    "    model = module.load(modelpath)\n",
    "    plot_env(env, num_steps_env=num_steps_env, model=model, name=f'{algo} on {task}', fig_kwargs={'figsize':(10, 12)})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "files = sorted([str(x) for x in Path('/home/jordi/Repos/pkgs/data/3rd/').glob('*0/model.zip')])\n",
    "for f in files:\n",
    "    custom_plot_env(f, num_steps_env=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#custom_plot_env('A2C', )\n",
    "import shutil\n",
    "dest_dir = '/home/jordi/DATA/Documents/remote_code/share/'\n",
    "\n",
    "if not os.path.exists(dest_dir):\n",
    "    os.makedirs(dest_dir)\n",
    "\n",
    "for f in files:\n",
    "    mod = f.split('/')[-2]\n",
    "    if not os.path.exists(dest_dir+mod+'/'):\n",
    "        os.makedirs(dest_dir+mod+'/')\n",
    "    shutil.copyfile(f, dest_dir+mod+'/model.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "custom_plot_env('/home/jordi/Repos/pkgs/trash/A2C_DelayedMatchCategory-v0_0/model.zip', num_steps_env=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# targ\n",
    "#toplot = '/home/jordi/Repos/pkgs/trash/A2C_DelayedMatchCategory-v0_0/DelayedMatchCategory_bhvr_data_149000.npz'\n",
    "#toplot = '/home/jordi/Repos/pkgs/trash/A2C_DelayedComparison-v0_0/DelayedComparison_bhvr_data_140000.npz'\n",
    "toplot = '/home/jordi/Repos/pkgs/data/3rd/A2C_DelayedComparison-v0_0/DelayedComparison_bhvr_data_100000.npz'\n",
    "toplot = np.load(toplot, allow_pickle=True)\n",
    "toplot.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "acts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "obs = toplot['stimulus']\n",
    "gt = toplot['gt']\n",
    "acts = toplot['choice']\n",
    "rews = toplot['reward']\n",
    "nsteps=100\n",
    "f, ax = plt.subplots(nrows=3, ncols=1, figsize=(9,10), sharex=True)\n",
    "ax[0].imshow(obs[-nsteps:,:].T, aspect='auto')\n",
    "ax[0].set_title('DelayedComparison')\n",
    "ax[0].set_ylabel('obs')\n",
    "ax[1].plot(acts[-nsteps:], c='tab:blue', marker='+')\n",
    "ax[1].plot(gt[-nsteps:], c='tab:red')\n",
    "ax[1].set_ylabel('acts')\n",
    "ax[2].plot(rews[-nsteps:], c='tab:red')\n",
    "ax[2].set_ylabel('rews')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# so model actually learns (according to monitor wrapper)the issue is somewhere when reusing plotting functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what's wrong when reusing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"3\"\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.FATAL)\n",
    "\n",
    "from stable_baselines import A2C\n",
    "from stable_baselines.common.policies import LstmPolicy\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "import gym\n",
    "import neurogym \n",
    "from neurogym.utils.plotting import plot_env\n",
    "import importlib\n",
    "\n",
    "from neurogym.custom_timings import ALL_ENVS_MINIMAL_TIMINGS\n",
    "\n",
    "def custom_plot_env(modelpath, num_steps_env=100):\n",
    "    root_str = os.path.split(modelpath)[0].split('/')[-1]\n",
    "    algo = root_str.split('_')[0]\n",
    "    task = root_str.split('_')[1]\n",
    "    seed = root_str.split('_')[-1]\n",
    "    ngym_kwargs = {'dt':100, 'timing': ALL_ENVS_MINIMAL_TIMINGS[task]}\n",
    "    env = gym.make(task, **ngym_kwargs)\n",
    "    env = DummyVecEnv([lambda: env])\n",
    "    pkg = importlib.import_module('stable_baselines') #+algo) \n",
    "    module = getattr(pkg, algo)\n",
    "    ###new shit\n",
    "    model = module(LstmPolicy, env, verbose=0, n_steps=20, n_cpu_tf_sess=1, policy_kwargs={'feature_extraction':'mlp'}) \n",
    "    ###\n",
    "    model = module.load(modelpath)\n",
    "    plot_env(env, num_steps_env=num_steps_env, model=model, name=f'{algo} on {task}', fig_kwargs={'figsize':(10, 12)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toplot = '/home/jordi/Repos/pkgs/data/3rd/A2C_DelayedComparison-v0_0/model.zip' #DelayedComparison_bhvr_data_100000.npz'\n",
    "#toplot = '/home/jordi/Repos/pkgs/data/3rd/A2C_DelayedMatchToSampleDistractor1D-v0_0/model.zip'\n",
    "#toplot = '/home/jordi/Repos/pkgs/data/3rd/A2C_DelayedMatchCategory-v0_0/model.zip'\n",
    "custom_plot_env(toplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i still do not know why, when saving monitor everyingle iter it looks as it is learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learning RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"3\"\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.FATAL)\n",
    "\n",
    "from stable_baselines import A2C\n",
    "from stable_baselines.common.policies import LstmPolicy\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "import gym\n",
    "import neurogym \n",
    "from neurogym.utils.plotting import plot_env\n",
    "import importlib\n",
    "\n",
    "from neurogym.custom_timings import ALL_ENVS_MINIMAL_TIMINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = sorted(list(ALL_ENVS_MINIMAL_TIMINGS.keys()))\n",
    "motherdir='/home/jordi/Repos/pkgs/data/3rd/'\n",
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth = motherdir+f'A2C_{tasks[0]}_0/'\n",
    "\n",
    "f, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "neurogym.utils.plotting.plot_rew_across_training(pth, window=0.05,ax=ax, fkwargs={'c':'tab:orange', 'ls':'--', 'alpha':0.5, 'label':'test'})\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#len(tasks)\n",
    "f, ax = plt.subplots(nrows=13, ncols=2, figsize=(18, 13*3))\n",
    "ax = ax.flatten()\n",
    "cols = sns.color_palette()\n",
    "for i, task in enumerate(tasks):\n",
    "    for j,alg in enumerate(['A2C', 'ACER', 'PPO2']):\n",
    "        for k in [0,1]:\n",
    "            pth = f'{motherdir}{alg}_{task}_{k}/'\n",
    "            try:\n",
    "                neurogym.utils.plotting.plot_rew_across_training(pth, window=0.05,ax=ax[i], fkwargs={'c':cols[j], 'ls':'--', 'alpha':0.5, 'label':alg},\n",
    "                                                                 ytitle=task, legend=True, zline=True)\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "#plt.legend()\n",
    "plt.suptitle('bsc training Jan3rd')\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.savefig('./monster.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
